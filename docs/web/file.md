大文件上传
核心
Blob.prototype.slice

思路
前端
1. 设置切片的最大数量，将文件切分成一个个小的切片
2. 同时上传多个小切片
3. 并发上传可能会导致上传到服务器的顺序发生变化，因此需要给每个切片记录顺序


服务端
1. 接收切片
2. 合并切片
   2.1 方法1：前端需要在切片中携带切片最大数量的信息，当服务端接收到这个数量的切片时，自动合并
   2.2 方法2：前端发送一个请求通知服务端进行切片的合并

   合并实现
   nodejs：使用nodejs的读写流(readStream/writeStream), 将所有切片的流传输到最终的文件流里


实现过程
const SIZE = 10 * 1024 * 1024; // 切片大小


断点续传
原理：前端/服务端需要记住已上传的切片，这样下次上传就可以跳过之前已上传的部分
方案1：前端使用localStorStorge记录已上传的切片Hash   （缺点：换了浏览器就失去了记忆效果）
方案2：服务端保存已上传文件的hash，前端每次上传前向服务端获取已上传的切片


hash生成方式：
方案1：文件名+切片下标 （缺点：文件名一但修改就失去了效果）
方案2：根据文件内容生成hash


spark-md5：可以根据文件内容计算出文件的hash值
读取文件内容计算 hash 是非常耗费时间的，并且会引起 UI 的阻塞，导致页面假死状态，所以我们使用 web-worker 在 worker 线程计算 hash









