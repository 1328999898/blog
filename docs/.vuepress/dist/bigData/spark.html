<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Spark | 我的博客</title>
    <meta name="generator" content="VuePress 1.4.1">
    
    <meta name="description" content="">
    <meta name="theme-color" content="#3eaf7c">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="preload" href="/blog/assets/css/0.styles.a4a57897.css" as="style"><link rel="preload" href="/blog/assets/js/app.48b65c17.js" as="script"><link rel="preload" href="/blog/assets/js/2.7ae4b6a2.js" as="script"><link rel="preload" href="/blog/assets/js/31.8bc7ae14.js" as="script"><link rel="prefetch" href="/blog/assets/js/10.b9968e70.js"><link rel="prefetch" href="/blog/assets/js/100.d0e2957b.js"><link rel="prefetch" href="/blog/assets/js/101.b2abaa15.js"><link rel="prefetch" href="/blog/assets/js/102.c5741f26.js"><link rel="prefetch" href="/blog/assets/js/103.59154d21.js"><link rel="prefetch" href="/blog/assets/js/104.8dd71d52.js"><link rel="prefetch" href="/blog/assets/js/105.6a9d0b55.js"><link rel="prefetch" href="/blog/assets/js/11.346cfd8a.js"><link rel="prefetch" href="/blog/assets/js/12.ec696b07.js"><link rel="prefetch" href="/blog/assets/js/13.503fd6a4.js"><link rel="prefetch" href="/blog/assets/js/14.56121eb9.js"><link rel="prefetch" href="/blog/assets/js/15.0879e1c6.js"><link rel="prefetch" href="/blog/assets/js/16.6cd50b21.js"><link rel="prefetch" href="/blog/assets/js/17.b8d3e4ae.js"><link rel="prefetch" href="/blog/assets/js/18.afc9723b.js"><link rel="prefetch" href="/blog/assets/js/19.30d39ecf.js"><link rel="prefetch" href="/blog/assets/js/20.3f07f483.js"><link rel="prefetch" href="/blog/assets/js/21.85aeac5c.js"><link rel="prefetch" href="/blog/assets/js/22.5f85175f.js"><link rel="prefetch" href="/blog/assets/js/23.5cce27da.js"><link rel="prefetch" href="/blog/assets/js/24.10e666f4.js"><link rel="prefetch" href="/blog/assets/js/25.1ee75104.js"><link rel="prefetch" href="/blog/assets/js/26.68c8fd74.js"><link rel="prefetch" href="/blog/assets/js/27.3060915d.js"><link rel="prefetch" href="/blog/assets/js/28.baef18fc.js"><link rel="prefetch" href="/blog/assets/js/29.cfaeb753.js"><link rel="prefetch" href="/blog/assets/js/3.e34a90bc.js"><link rel="prefetch" href="/blog/assets/js/30.5c3349d4.js"><link rel="prefetch" href="/blog/assets/js/32.f8d216ee.js"><link rel="prefetch" href="/blog/assets/js/33.779315c6.js"><link rel="prefetch" href="/blog/assets/js/34.62cfea40.js"><link rel="prefetch" href="/blog/assets/js/35.cf895c9c.js"><link rel="prefetch" href="/blog/assets/js/36.8c701a66.js"><link rel="prefetch" href="/blog/assets/js/37.953a636d.js"><link rel="prefetch" href="/blog/assets/js/38.735fc60b.js"><link rel="prefetch" href="/blog/assets/js/39.267c12a9.js"><link rel="prefetch" href="/blog/assets/js/4.3aabfd60.js"><link rel="prefetch" href="/blog/assets/js/40.97e69ef5.js"><link rel="prefetch" href="/blog/assets/js/41.869ff4e6.js"><link rel="prefetch" href="/blog/assets/js/42.a5a88b22.js"><link rel="prefetch" href="/blog/assets/js/43.52fe9ca4.js"><link rel="prefetch" href="/blog/assets/js/44.5c850de7.js"><link rel="prefetch" href="/blog/assets/js/45.80564d93.js"><link rel="prefetch" href="/blog/assets/js/46.8a357da1.js"><link rel="prefetch" href="/blog/assets/js/47.213252e2.js"><link rel="prefetch" href="/blog/assets/js/48.b5e92311.js"><link rel="prefetch" href="/blog/assets/js/49.b80e0be0.js"><link rel="prefetch" href="/blog/assets/js/5.2e8e35bb.js"><link rel="prefetch" href="/blog/assets/js/50.ecb5ea0b.js"><link rel="prefetch" href="/blog/assets/js/51.9613210b.js"><link rel="prefetch" href="/blog/assets/js/52.e3110a1b.js"><link rel="prefetch" href="/blog/assets/js/53.f2ba567d.js"><link rel="prefetch" href="/blog/assets/js/54.ab1864eb.js"><link rel="prefetch" href="/blog/assets/js/55.86c0c32f.js"><link rel="prefetch" href="/blog/assets/js/56.c20f3561.js"><link rel="prefetch" href="/blog/assets/js/57.317263a6.js"><link rel="prefetch" href="/blog/assets/js/58.73936df2.js"><link rel="prefetch" href="/blog/assets/js/59.125c9aa4.js"><link rel="prefetch" href="/blog/assets/js/6.3a266898.js"><link rel="prefetch" href="/blog/assets/js/60.b47b46e1.js"><link rel="prefetch" href="/blog/assets/js/61.abe8abde.js"><link rel="prefetch" href="/blog/assets/js/62.1245636d.js"><link rel="prefetch" href="/blog/assets/js/63.2627e8ac.js"><link rel="prefetch" href="/blog/assets/js/64.585b9303.js"><link rel="prefetch" href="/blog/assets/js/65.c81ac681.js"><link rel="prefetch" href="/blog/assets/js/66.f96cd1fb.js"><link rel="prefetch" href="/blog/assets/js/67.327ce355.js"><link rel="prefetch" href="/blog/assets/js/68.87bbefa9.js"><link rel="prefetch" href="/blog/assets/js/69.afb5bc80.js"><link rel="prefetch" href="/blog/assets/js/7.2de9b0d5.js"><link rel="prefetch" href="/blog/assets/js/70.67fc265c.js"><link rel="prefetch" href="/blog/assets/js/71.6ae7b02f.js"><link rel="prefetch" href="/blog/assets/js/72.712dce12.js"><link rel="prefetch" href="/blog/assets/js/73.c2816fc6.js"><link rel="prefetch" href="/blog/assets/js/74.1b3b92f4.js"><link rel="prefetch" href="/blog/assets/js/75.585d8acd.js"><link rel="prefetch" href="/blog/assets/js/76.4223ccd0.js"><link rel="prefetch" href="/blog/assets/js/77.e5f55e34.js"><link rel="prefetch" href="/blog/assets/js/78.e9ee6aea.js"><link rel="prefetch" href="/blog/assets/js/79.fed44daa.js"><link rel="prefetch" href="/blog/assets/js/8.a4c35f86.js"><link rel="prefetch" href="/blog/assets/js/80.ee7b8747.js"><link rel="prefetch" href="/blog/assets/js/81.88386f31.js"><link rel="prefetch" href="/blog/assets/js/82.4af9fb1d.js"><link rel="prefetch" href="/blog/assets/js/83.da9da420.js"><link rel="prefetch" href="/blog/assets/js/84.42fbb450.js"><link rel="prefetch" href="/blog/assets/js/85.6306c2bc.js"><link rel="prefetch" href="/blog/assets/js/86.c899362a.js"><link rel="prefetch" href="/blog/assets/js/87.f6322c17.js"><link rel="prefetch" href="/blog/assets/js/88.eddc0942.js"><link rel="prefetch" href="/blog/assets/js/89.165da529.js"><link rel="prefetch" href="/blog/assets/js/9.abcbd242.js"><link rel="prefetch" href="/blog/assets/js/90.268f179d.js"><link rel="prefetch" href="/blog/assets/js/91.180d5bbe.js"><link rel="prefetch" href="/blog/assets/js/92.a4144934.js"><link rel="prefetch" href="/blog/assets/js/93.f53cb5ac.js"><link rel="prefetch" href="/blog/assets/js/94.10c79220.js"><link rel="prefetch" href="/blog/assets/js/95.6748f0b8.js"><link rel="prefetch" href="/blog/assets/js/96.e2037716.js"><link rel="prefetch" href="/blog/assets/js/97.b2460e8d.js"><link rel="prefetch" href="/blog/assets/js/98.021d7d73.js"><link rel="prefetch" href="/blog/assets/js/99.eefede02.js">
    <link rel="stylesheet" href="/blog/assets/css/0.styles.a4a57897.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/blog/" class="home-link router-link-active"><!----> <span class="site-name">我的博客</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/blog/web/" class="nav-link">
  Web
</a></div><div class="nav-item"><a href="/blog/vue/" class="nav-link">
  VUE
</a></div><div class="nav-item"><a href="/blog/bigData/" class="nav-link router-link-active">
  后端
</a></div><div class="nav-item"><a href="/blog/git/" class="nav-link">
  Git
</a></div><div class="nav-item"><a href="/blog/install/" class="nav-link">
  安装
</a></div><div class="nav-item"><a href="/blog/other/" class="nav-link">
  其他
</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/blog/web/" class="nav-link">
  Web
</a></div><div class="nav-item"><a href="/blog/vue/" class="nav-link">
  VUE
</a></div><div class="nav-item"><a href="/blog/bigData/" class="nav-link router-link-active">
  后端
</a></div><div class="nav-item"><a href="/blog/git/" class="nav-link">
  Git
</a></div><div class="nav-item"><a href="/blog/install/" class="nav-link">
  安装
</a></div><div class="nav-item"><a href="/blog/other/" class="nav-link">
  其他
</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>后端技术总结</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/blog/bigData/" class="sidebar-link">Introduction</a></li><li><a href="/blog/bigData/mysql.html" class="sidebar-link">MySql</a></li><li><a href="/blog/bigData/redis.html" class="sidebar-link">redis基础</a></li><li><a href="/blog/bigData/es.html" class="sidebar-link">Elasticsearch</a></li><li><a href="/blog/bigData/kylin.html" class="sidebar-link">Kylin知识整理</a></li><li><a href="/blog/bigData/hybrid.html" class="sidebar-link">hybrid优化总结</a></li><li><a href="/blog/bigData/python.html" class="sidebar-link">Python</a></li><li><a href="/blog/bigData/pandas.html" class="sidebar-link">pandas</a></li><li><a href="/blog/bigData/django.html" class="sidebar-link">Django</a></li><li><a href="/blog/bigData/linux.html" class="sidebar-link">Linux基础</a></li><li><a href="/blog/bigData/nginx.html" class="sidebar-link">Nginx配置</a></li><li><a href="/blog/bigData/aws-s3.html" class="sidebar-link">aws s3 命令</a></li><li><a href="/blog/bigData/hive.html" class="sidebar-link">hive</a></li><li><a href="/blog/bigData/hdfs.html" class="sidebar-link">DHFS基础</a></li><li><a href="/blog/bigData/hbase.html" class="sidebar-link">HBASE</a></li><li><a href="/blog/bigData/spark.html" class="active sidebar-link">Spark</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/blog/bigData/spark.html#速度-speed" class="sidebar-link">速度(speed)</a></li><li class="sidebar-sub-header"><a href="/blog/bigData/spark.html#易于使用" class="sidebar-link">易于使用</a></li><li class="sidebar-sub-header"><a href="/blog/bigData/spark.html#常规性" class="sidebar-link">常规性</a></li><li class="sidebar-sub-header"><a href="/blog/bigData/spark.html#运行环境" class="sidebar-link">运行环境</a></li><li class="sidebar-sub-header"><a href="/blog/bigData/spark.html#在hadoop之上构建的spark" class="sidebar-link">在Hadoop之上构建的Spark</a></li><li class="sidebar-sub-header"><a href="/blog/bigData/spark.html#其他" class="sidebar-link">其他</a></li><li class="sidebar-sub-header"><a href="/blog/bigData/spark.html#总结" class="sidebar-link">总结</a></li><li class="sidebar-sub-header"><a href="/blog/bigData/spark.html#一、弹性分布式数据集rdd" class="sidebar-link">一、弹性分布式数据集RDD</a></li><li class="sidebar-sub-header"><a href="/blog/bigData/spark.html#二、rdd操作" class="sidebar-link">二、RDD操作</a></li><li class="sidebar-sub-header"><a href="/blog/bigData/spark.html#三、共享变量" class="sidebar-link">三、共享变量</a></li><li class="sidebar-sub-header"><a href="/blog/bigData/spark.html#sparksession" class="sidebar-link">SparkSession</a></li><li class="sidebar-sub-header"><a href="/blog/bigData/spark.html#rdd的两种计算方式" class="sidebar-link">RDD的两种计算方式</a></li><li class="sidebar-sub-header"><a href="/blog/bigData/spark.html#shuffle操作实例" class="sidebar-link">shuffle操作实例</a></li><li class="sidebar-sub-header"><a href="/blog/bigData/spark.html#spark读书笔记" class="sidebar-link">spark读书笔记</a></li></ul></li><li><a href="/blog/bigData/luigi.html" class="sidebar-link">Luigi和sciluigi</a></li><li><a href="/blog/bigData/scala.html" class="sidebar-link">scala基础</a></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="spark"><a href="#spark" class="header-anchor">#</a> Spark</h1> <p>快如闪电的集群计算，是快速和通用的大规模集群技术。</p> <ul><li><a href="http://www.apache.org" target="_blank" rel="noopener noreferrer">apache官网<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li><a href="http://spark.apache.org" target="_blank" rel="noopener noreferrer">spark官网<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li><a href="https://www.iteblog.com/archives/1673.html" target="_blank" rel="noopener noreferrer">SparkSession<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li><a href="https://github.com/alibaba/fastjson/wiki/JSON_API_cn" target="_blank" rel="noopener noreferrer">JSON API<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li><a href="http://colobu.com/2014/12/08/spark-programming-guide/#%E7%AE%80%E4%BB%8B" target="_blank" rel="noopener noreferrer">Spark开发指南<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li><a href="http://www.cnblogs.com/shishanyuan/category/719232.html" target="_blank" rel="noopener noreferrer">石山园<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul> <h2 id="速度-speed"><a href="#速度-speed" class="header-anchor">#</a> 速度(speed)</h2> <ul><li>在内存中执行mr作业比Hadoop快100倍</li> <li>在磁盘上比Hadoop快10倍</li> <li>spark有DAG(有向无环图)执行引擎，支持高数据流和内存计算。</li></ul> <h2 id="易于使用"><a href="#易于使用" class="header-anchor">#</a> 易于使用</h2> <ul><li>支持多种语言：Java、Scala、python、R</li> <li>提供了80多种高级操作用于并行APP，可以使用脚本语言进行交互式编程。</li></ul> <h2 id="常规性"><a href="#常规性" class="header-anchor">#</a> 常规性</h2> <ul><li>合成SQL语句</li> <li>流计算</li> <li>复杂分析</li> <li>MLIB(机器学习类库)</li> <li>GraphX(图形计算)</li> <li>spark数据流</li></ul> <h2 id="运行环境"><a href="#运行环境" class="header-anchor">#</a> 运行环境</h2> <ul><li>可运行环境：Hadoop、Mesos、standalone、cloud</li> <li>可访问的数据源：HDFS、Cassandra、Hbase、S3(亚马逊的分布式文件系统)</li></ul> <h2 id="在hadoop之上构建的spark"><a href="#在hadoop之上构建的spark" class="header-anchor">#</a> 在Hadoop之上构建的Spark</h2> <blockquote><p>Yarn（资源调度框架）</p></blockquote> <p>spark部署的三种模式：</p> <ul><li>standalone（独立模式）
<ul><li>在hdfs之上分配空间，spark和mr同时运行，覆盖到所有的job</li></ul></li> <li>Hadoop Yarn（Hadoop v2.x）
<ul><li>在yarn上运行</li> <li>不需要预安装或者要求root访问</li> <li>有助于spark和Hadoop生态系统进行集成（Hadoop栈），也允许其他组件在栈之上运行</li></ul></li> <li>spark in mapreduce（Hadoop v1.x）</li></ul> <h2 id="其他"><a href="#其他" class="header-anchor">#</a> 其他</h2> <ul><li>spark有自己的集群管理机制，基于Hadoop mr模型并且扩展了Hadoop mr模型用于高效计算</li> <li>包括交互式查询和流计算</li> <li>主要特性：内存的集群计算（内存一定要足够大）</li> <li>可以使用一些单独的工具，减少维护的成本</li> <li>spark使用Hadoop有2种方式：1.存储，2.处理</li> <li>由于spark有自己的集群管理，所以使用Hadoop只是为了存储。</li></ul> <h2 id="总结"><a href="#总结" class="header-anchor">#</a> 总结</h2> <ul><li>RDD(弹性分布式数据集，resilient distributed dataset)，有容错机制并可以被并行操作的元素集合。</li> <li>共享变量（两种）：1）广播变量：可以在内存的所有节点上缓存变量。 2）累加器：只能用于做加法（例如：计数、求和）</li></ul> <h2 id="一、弹性分布式数据集rdd"><a href="#一、弹性分布式数据集rdd" class="header-anchor">#</a> 一、弹性分布式数据集RDD</h2> <ul><li>并行集合（parallielized collections）
并行集合：在已存在的scala集合，通过调用SparkContext的parallelize方法创建的可以被并行操作的分布式数据集。</li></ul> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token comment">/**
创建分布式数据集
**/</span>
<span class="token keyword">val</span> data<span class="token operator">=</span>Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> DisData <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
<span class="token comment">/**
并行操作分布式数据集：进行相加操作
**/</span>
DisData<span class="token punctuation">.</span>reduce<span class="token punctuation">(</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token keyword">=&gt;</span> a<span class="token operator">+</span>b<span class="token punctuation">)</span>
<span class="token comment">/**
sc.parallelize(data, slices)，其中slices表示数据集切分的分数，默认Spark会根据集群的状况自动设定slices的数目。也可以手动传入slices设置
**/</span>
<span class="token keyword">val</span> DisData <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>data<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>
</code></pre></div><ul><li>外部数据集（External Datasets）
通过Hadoop支持的文件系统创建数据集，文件包括：本地文件、hdfs、cassandra、hbase、s3等，文件格式：TextFile、SequenceFiles等。文件输入法包括：textFile、文件夹、压缩文件和通配符。</li></ul> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token comment">/**
TextFile的RDD可以通过SparkContext的textFile方式创建，但是数据集并没有加载到内存中，只是指向文件的索引
**/</span>
<span class="token keyword">val</span> distFile <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;/path/filename&quot;</span><span class="token punctuation">)</span>
<span class="token comment">/**
数据集操作：将所有数据行的长度相加，lineLengths：定义行长度，行长度由于惰性设计并没有立即计算；reduce：运行reduce时，Spark将计算分解成运行在各个节点的任务，每个节点运行它的map以及本地的reduction，并将结果返回给驱动城区
**/</span>
<span class="token keyword">val</span> lineLengths <span class="token operator">=</span> distFile<span class="token punctuation">.</span>map<span class="token punctuation">(</span>s <span class="token keyword">=&gt;</span> s<span class="token punctuation">.</span>length<span class="token punctuation">)</span>
<span class="token keyword">val</span> totalLength <span class="token operator">=</span> lineLengths<span class="token punctuation">.</span>reduce<span class="token punctuation">(</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> a <span class="token operator">+</span> b<span class="token punctuation">)</span>
</code></pre></div><h2 id="二、rdd操作"><a href="#二、rdd操作" class="header-anchor">#</a> 二、RDD操作</h2> <ul><li>转换：从现有数据集创建一个新的数据集（例如：map，传递数据集的每个元素并返回新的分布式数据集表示结果）</li> <li>动作：在数据集上运行计算后，返回一个值给驱动程序(例如：reduce，通过一些函数将所有元素叠加起来，并将最终结果返回给Driver程序。reduceByKey，返回分布式数据集)</li></ul> <h2 id="三、共享变量"><a href="#三、共享变量" class="header-anchor">#</a> 三、共享变量</h2> <ul><li>广播变量
广播变量允许程序员保留一个只读的变量，缓存在每一台机器上</li></ul> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token comment">/**
广播变量的创建，对象v不能在广播后修改，这样可以保证所有节点收到的广播值一致
**/</span>
scala<span class="token operator">&gt;</span> <span class="token keyword">val</span> v<span class="token operator">=</span>Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
v<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
scala<span class="token operator">&gt;</span> <span class="token keyword">var</span> broadvalue <span class="token operator">=</span> sc<span class="token punctuation">.</span>broadcast<span class="token punctuation">(</span>v<span class="token punctuation">)</span>
broadvalue<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>broadcast<span class="token punctuation">.</span>Broadcast<span class="token punctuation">[</span>Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> Broadcast<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span>

<span class="token comment">/**
广播变量的调用
**/</span>
scala<span class="token operator">&gt;</span> <span class="token keyword">var</span> mm <span class="token operator">=</span> broadvalue<span class="token punctuation">.</span>value
mm<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
</code></pre></div><ul><li>累计器
通过关联操作进行加操作的变量，可以高效并行支持</li></ul> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token comment">/**
创建累加器，并赋初始值10
**/</span>
scala<span class="token operator">&gt;</span> <span class="token keyword">val</span> accum <span class="token operator">=</span> sc<span class="token punctuation">.</span>accumulator<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token string">&quot;aa&quot;</span><span class="token punctuation">)</span>
warning<span class="token operator">:</span> there were two deprecation warnings<span class="token punctuation">;</span> re<span class="token operator">-</span>run <span class="token keyword">with</span> <span class="token operator">-</span>deprecation <span class="token keyword">for</span> details
accum<span class="token operator">:</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>Accumulator<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">10</span>
<span class="token comment">/**
使用累加器相加
**/</span>
scala<span class="token operator">&gt;</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>v<span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>x<span class="token keyword">=&gt;</span>accum<span class="token operator">+=</span>x<span class="token punctuation">)</span>
scala<span class="token operator">&gt;</span> accum<span class="token punctuation">.</span>value
res68<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token number">21</span>
</code></pre></div><h2 id="sparksession"><a href="#sparksession" class="header-anchor">#</a> SparkSession</h2> <blockquote><p>SparkSession是spark2.0引入的新概念，早期的版本中SparkContext是spark的主要入口点，RDD是主要的API，通过SparkContext来创建和操作RDD，对于每个其他的API我们都需要使用不同的context，如：StreamingContext、sqlContext、hiveContext
在spark2.0中，引入SparkSession作为DataSet和DataFrame API的新的入口点，SparkSession封装了SparkConf、SparkContext、SQLContext、HiveContext</p></blockquote> <ul><li>创建SparkSession</li></ul> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token comment">/**
使用local创建SparkContext，并包装它的SQLContext,
**/</span>
<span class="token keyword">val</span> sparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">&quot;local&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">&quot;spark session example&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">/**
使用spark会话从csv读取数据
**/</span>
<span class="token keyword">val</span> df <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>read<span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">&quot;header&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;true&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>csv<span class="token punctuation">(</span><span class="token string">&quot;src/main/resources/sales.csv&quot;</span><span class="token punctuation">)</span>
<span class="token comment">/**
使用textFile加载文件创建RDD
**/</span>
<span class="token keyword">val</span> lines <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">'path'</span><span class="token punctuation">)</span>
</code></pre></div><ul><li>mutable.HashMap</li></ul> <div class="language-scala extra-class"><pre class="language-scala"><code><span class="token comment">/**
相当于字典
**/</span>
scala<span class="token operator">&gt;</span> <span class="token keyword">val</span> map <span class="token operator">=</span> scala<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>mutable<span class="token punctuation">.</span>HashMap<span class="token punctuation">.</span>empty<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">,</span><span class="token builtin">String</span><span class="token punctuation">]</span>
map<span class="token operator">:</span> scala<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>mutable<span class="token punctuation">.</span>HashMap<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">,</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> Map<span class="token punctuation">(</span><span class="token punctuation">)</span>
scala<span class="token operator">&gt;</span> map <span class="token operator">+=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-&gt;</span> <span class="token string">&quot;make a web site&quot;</span><span class="token punctuation">)</span>
res42<span class="token operator">:</span> map<span class="token punctuation">.</span><span class="token keyword">type</span> <span class="token operator">=</span> Map<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-&gt;</span> make a web site<span class="token punctuation">)</span>
scala<span class="token operator">&gt;</span> map <span class="token operator">+=</span> <span class="token punctuation">(</span><span class="token number">3</span> <span class="token operator">-&gt;</span> <span class="token string">&quot;profit!&quot;</span><span class="token punctuation">)</span>
res43<span class="token operator">:</span> map<span class="token punctuation">.</span><span class="token keyword">type</span> <span class="token operator">=</span> Map<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-&gt;</span> make a web site<span class="token punctuation">,</span> <span class="token number">3</span> <span class="token operator">-&gt;</span> profit<span class="token operator">!</span><span class="token punctuation">)</span>
scala<span class="token operator">&gt;</span> map<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
res44<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> make a web site
scala<span class="token operator">&gt;</span> map contains <span class="token number">2</span>
res46<span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token boolean">false</span>
scala<span class="token operator">&gt;</span> map<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token string">&quot;444&quot;</span><span class="token punctuation">)</span>
res43<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> profit<span class="token operator">!</span>
scala<span class="token operator">&gt;</span> tt<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token string">&quot;444&quot;</span><span class="token punctuation">)</span>
res44<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> <span class="token number">444</span>
</code></pre></div><h2 id="rdd的两种计算方式"><a href="#rdd的两种计算方式" class="header-anchor">#</a> RDD的两种计算方式</h2> <ul><li>转换：返回值是一个RDD</li> <li>操作：返回值不是一个RDD</li></ul> <h2 id="shuffle操作实例"><a href="#shuffle操作实例" class="header-anchor">#</a> shuffle操作实例</h2> <div class="language-sh extra-class"><pre class="language-sh"><code>scala<span class="token operator">&gt;</span> val kv1 <span class="token operator">=</span> sc.parallelize<span class="token punctuation">(</span>List<span class="token variable"><span class="token punctuation">((</span>&quot;A&quot;<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>&quot;B&quot;<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>&quot;C&quot;<span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span>&quot;A&quot;<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>&quot;B&quot;<span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">))</span></span><span class="token punctuation">)</span>
kv1: org.apache.spark.rdd.RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>String, Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">17</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">&gt;</span>:24

scala<span class="token operator">&gt;</span> kv1.sortByKey<span class="token punctuation">(</span><span class="token punctuation">)</span>.collect<span class="token punctuation">(</span><span class="token punctuation">)</span>
res33: Array<span class="token punctuation">[</span><span class="token punctuation">(</span>String, Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token variable"><span class="token punctuation">((</span>A<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>A<span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>B<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>B<span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>C<span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">))</span></span>

scala<span class="token operator">&gt;</span> kv1.groupByKey<span class="token punctuation">(</span><span class="token punctuation">)</span>.collect<span class="token punctuation">(</span><span class="token punctuation">)</span>
res34: Array<span class="token punctuation">[</span><span class="token punctuation">(</span>String, Iterable<span class="token punctuation">[</span>Int<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token variable"><span class="token punctuation">((</span>A<span class="token punctuation">,</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">))</span></span>, <span class="token punctuation">(</span>B,CompactBuffer<span class="token punctuation">(</span><span class="token number">2</span>, <span class="token number">5</span><span class="token punctuation">))</span>, <span class="token punctuation">(</span>C,CompactBuffer<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">))</span><span class="token punctuation">)</span>

scala<span class="token operator">&gt;</span> kv1.reduceByKey<span class="token punctuation">(</span>_+_<span class="token punctuation">)</span>.collect<span class="token punctuation">(</span><span class="token punctuation">)</span>
res35: Array<span class="token punctuation">[</span><span class="token punctuation">(</span>String, Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token variable"><span class="token punctuation">((</span>A<span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>B<span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>C<span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">))</span></span>
</code></pre></div><ul><li>distinct、union、</li></ul> <div class="language-sh extra-class"><pre class="language-sh"><code>scala<span class="token operator">&gt;</span> val <span class="token assign-left variable">kv2</span><span class="token operator">=</span>sc.parallelize<span class="token punctuation">(</span>List<span class="token variable"><span class="token punctuation">((</span>&quot;A&quot;<span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span>&quot;A&quot;<span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span>&quot;C&quot;<span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span>&quot;A&quot;<span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span>&quot;B&quot;<span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">))</span></span><span class="token punctuation">)</span>
kv2: org.apache.spark.rdd.RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>String, Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">23</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">&gt;</span>:24

scala<span class="token operator">&gt;</span> kv2.distinct.collect<span class="token punctuation">(</span><span class="token punctuation">)</span>
res36: Array<span class="token punctuation">[</span><span class="token punctuation">(</span>String, Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token variable"><span class="token punctuation">((</span>A<span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>B<span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>C<span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">))</span></span>

scala<span class="token operator">&gt;</span> kv1.union<span class="token punctuation">(</span>kv2<span class="token punctuation">)</span>.collect<span class="token punctuation">(</span><span class="token punctuation">)</span>
res38: Array<span class="token punctuation">[</span><span class="token punctuation">(</span>String, Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token variable"><span class="token punctuation">((</span>A<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>B<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>C<span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>A<span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>B<span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>A<span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>A<span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>C<span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>A<span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>B<span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">))</span></span>

scala<span class="token operator">&gt;</span> val <span class="token assign-left variable">kv3</span><span class="token operator">=</span>sc.parallelize<span class="token punctuation">(</span>List<span class="token variable"><span class="token punctuation">((</span>&quot;A&quot;<span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span>&quot;B&quot;<span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span>&quot;D&quot;<span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">))</span></span><span class="token punctuation">)</span>
kv3: org.apache.spark.rdd.RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>String, Int<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">&gt;</span>:24

scala<span class="token operator">&gt;</span> kv1.join<span class="token punctuation">(</span>kv3<span class="token punctuation">)</span>.collect<span class="token punctuation">(</span><span class="token punctuation">)</span>
res42: Array<span class="token punctuation">[</span><span class="token punctuation">(</span>String, <span class="token punctuation">(</span>Int, Int<span class="token punctuation">))</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token variable"><span class="token punctuation">((</span>A<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">))</span></span>, <span class="token punctuation">(</span>A,<span class="token punctuation">(</span><span class="token number">4,10</span><span class="token punctuation">))</span>, <span class="token punctuation">(</span>B,<span class="token punctuation">(</span><span class="token number">2,20</span><span class="token punctuation">))</span>, <span class="token punctuation">(</span>B,<span class="token punctuation">(</span><span class="token number">5,20</span><span class="token punctuation">))</span><span class="token punctuation">)</span>

scala<span class="token operator">&gt;</span> kv1.cogroup<span class="token punctuation">(</span>kv3<span class="token punctuation">)</span>.collect<span class="token punctuation">(</span><span class="token punctuation">)</span>
res44: Array<span class="token punctuation">[</span><span class="token punctuation">(</span>String, <span class="token punctuation">(</span>Iterable<span class="token punctuation">[</span>Int<span class="token punctuation">]</span>, Iterable<span class="token punctuation">[</span>Int<span class="token punctuation">]</span><span class="token punctuation">))</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token variable"><span class="token punctuation">((</span>D<span class="token punctuation">,</span><span class="token punctuation">(</span>CompactBuffer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">))</span></span><span class="token punctuation">)</span>, <span class="token punctuation">(</span>A,<span class="token punctuation">(</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">1</span>, <span class="token number">4</span><span class="token punctuation">)</span>,CompactBuffer<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">))</span><span class="token punctuation">)</span>, <span class="token punctuation">(</span>B,<span class="token punctuation">(</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">2</span>, <span class="token number">5</span><span class="token punctuation">)</span>,CompactBuffer<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">))</span><span class="token punctuation">)</span>, <span class="token punctuation">(</span>C,<span class="token punctuation">(</span>CompactBuffer<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>,CompactBuffer<span class="token punctuation">(</span><span class="token punctuation">))</span><span class="token punctuation">))</span>

</code></pre></div><ul><li>yarn：资源调度框架</li></ul> <h2 id="spark读书笔记"><a href="#spark读书笔记" class="header-anchor">#</a> spark读书笔记</h2> <ul><li><a href="http://colobu.com/2014/12/09/spark-submitting-applications/" target="_blank" rel="noopener noreferrer">spark应用提交指南<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul> <p>spark三大优点：</p> <ol><li>笔记本电脑就可以开发spark应用</li> <li>速度快，支持交互是使用和复杂算法</li> <li>是一个通用引擎，可以用来完成各种各样的运算（SQL查询、文本处理、机器学习等）</li></ol> <p>spark运行方式：</p> <ol><li>本地模式运行：即非分布式模式</li> <li>mesos</li> <li>yarn</li> <li>spark发行版自带的独立调度器</li></ol> <div class="language- extra-class"><pre class="language-text"><code>获取帮助
spark-submit --help

spark操作：
创建RDD
转化已有RDD
调用RDD操作进行求值

spark SQL:结构化数据
spark streaming:实时计算
MLIB：机器学习
GraghX:图计算

RDD:弹性分布式数据集（resilient distributed dataset）
RDD是spark对分布式数据和计算的基本抽象

每个spark应用都是由一个驱动器程序来发起集群上的各种并行操作
驱动器程序通过一个SparkContext对象来访问spark，这代表对计算集群的一个连接
shell启动时自动创建了一个SparkContext对象，叫做sc

支持的语言
Java
scala
python
...


独立使用spark
shell 不需要自行初始化SparkContext
非shell 需要自行初始化SparkContext

Java和scala，需要给应用添加一个对于spark-core的工件的maven依赖


创建RDD
1.读取外部数据集
2.驱动器程序里分发驱动器程序中的对象集合


RDD操作
1.转化操作：一个RDD生成一个新的RDD
2.行动操作：对RDD计算出一个结果，并把结果返回到驱动器程序中，或者把结果存储到外部存储系统


RDD.persist() 缓存RDD，用于多个行动中重用同一个RDD
cache()与使用默认存储级别调用persist()是一样的

</code></pre></div><p>spark或shell会话的工作方式</p> <ol><li>从外部数据创建输入RDD</li> <li>使用诸如filter()这样的转化操作对RDD进行转化，以定义新的RDD</li> <li>告诉Spark对需要被重用的中间结果RDD执行persist()操作</li> <li>使用行动操作（例如count()和first()等）来出发一次并行计算，Spark会对计算进行优化后再执行</li></ol> <p>创建RDD</p> <ol><li>将程序中已有的集合传给sc.parallelize()方法
val lines = sc.parallize(List(&quot;aa&quot;, &quot;dsds&quot;))</li> <li>从外部存储中读取数据
val lines = sc.textFile(&quot;/path/file&quot;)</li></ol> <p>RDD操作</p> <ol><li>转化操作：返回RDD
map(), filter()
filter操作不会改变已有的RDD中的数据，该操作会返回一个全新的RDD
union合并两个RDD
val alines = lines.filter(line =&gt; line.contains(&quot;a&quot;))
val aaRDD = inputRDD.union(input)</li> <li>行动操作：返回其他数据类型
count(): 计数
first(): 获取第一行数据
take(2): 获取前两条数据
collect(): 返回整个RDD中的数据，只有整个数据集能在单台机器的内存中放得下时，才能使用collect()
saveAsTextFile()、saveAsSequenceFile() : 保存数据</li></ol> <p>Spark惰性求值</p> <div class="language- extra-class"><pre class="language-text"><code>在被调用行动操作之前Spark不会开始计算
Spark的惰性求值，可以把一些操作合并到一起来减少计算数据的步骤
Hadoop MapReduce系统中，开发者常常需要花大量时间考虑如何把操作组合到一起，以减少MapReduce的周期数
</code></pre></div><p>常用的转化操作</p> <div class="language- extra-class"><pre class="language-text"><code>map(): 接收一个函数，对RDD中的每个元素进行操作，将函数的返回结果作为结果RDD中的值
filter(): 接收一个函数，将RDD中满足该函数的元素放入新的RDD中返回
val nums = sc.parallelize(List(1,2,3,4))
val result = nums.map(x =&gt; x*x).collect().mkString(&quot;,&quot;)
// 输出结果： String = 1,4,9,16

flatMap(): 把行数据切分成单词
val lines = sc.parallelize(List(&quot;hello world&quot;, &quot;hi&quot;))
val words = lines.flatMap(line =&gt; line.split(&quot; &quot;))
// 输出结果：Array[String] = Array(hello, world, hi)


// 伪集合操作
// union 并集
scala&gt; val RDD1 = sc.parallelize(List(1,3,4,5))
scala&gt; val RDD2 = sc.parallelize(List(1,3,7,9))
scala&gt; RDD1.union(RDD2).collect()
res14: Array[Int] = Array(1, 3, 4, 5, 1, 3, 7, 9)
// intersection 交集
scala&gt; RDD1.intersection(RDD2).collect()
res15: Array[Int] = Array(1, 3)
// distinct 去重
scala&gt; val mm = RDD1.union(RDD2)
scala&gt; mm.distinct().collect()
res17: Array[Int] = Array(1, 9, 3, 4, 5, 7)
// subtract 差集
scala&gt; RDD1.subtract(RDD2).collect()
// cartesian 返回所有可能的笛卡尔积对
scala&gt; RDD1.cartesian(RDD2).collect()
res20: Array[(Int, Int)] = Array((1,1), (1,3), (1,7), (1,9), (3,1), (3,3), (3,7), (3,9), (4,1), (4,3), (4,7), (4,9), (5,1), (5,3), (5,7), (5,9))

// 行动函数
// 返回元素中的所有元素
scala&gt; RDD1.collect()
res30: Array[Int] = Array(1, 3, 4, 5)
// count 返回元素的个数
scala&gt; RDD1.count()
res29: Long = 4
// take 返回RDD中的n个元素
scala&gt; RDD1.take(2)
res26: Array[Int] = Array(1, 3)
// 按照顺序返回最前面的n个元素
scala&gt; RDD1.takeOrdered(2)
res31: Array[Int] = Array(1, 3)
// 返回任意n个元素
scala&gt; RDD1.takeSample(false, 2)
res33: Array[Int] = Array(3, 5)
// top() 获取前n个元素
scala&gt; RDD1.top(2)
res25: Array[Int] = Array(5, 4)
// countByValue 各元素在RDD中出现的次数
scala&gt; mm.countByValue()
res27: scala.collection.Map[Int,Long] = Map(5 -&gt; 1, 1 -&gt; 2, 9 -&gt; 1, 7 -&gt; 1, 3 -&gt; 2, 4 -&gt; 1)
</code></pre></div><p>不同RDD类型间转换</p> <div class="language- extra-class"><pre class="language-text"><code>数值RDD：mean()、variance()
键值对RDD：join()
scala中将RDD转为有特定功能的RDD是由隐式转换自动处理的：import org.apache.spark. SparkContext._

// 根据值筛选
scala&gt; RDD1.filter(x =&gt; x &lt; 4).collect()
res47: Array[Int] = Array(1, 3)

scala&gt; val data = Seq((&quot;a&quot;, 3), (&quot;b&quot;, 4), (&quot;a&quot;, 1))
data: Seq[(String, Int)] = List((a,3), (b,4), (a,1))
// reduceByKey
scala&gt; sc.parallelize(data).reduceByKey((x, y) =&gt; x + y).collect()
res49: Array[(String, Int)] = Array((a,4), (b,4))
</code></pre></div><p>spark支持多种数据源</p> <div class="language- extra-class"><pre class="language-text"><code>spark可以通过Hadoop MapReduce所使用的inputFormat和OutputFormat接口访问数据
支持的存储系统：s3、hdfs、Cassandra、HBASE等
支持的文件类型：json、sequenceFile、protocol buffer
可以连接的数据库：Cassandra、HBASE、elasticsearch、jdbc
</code></pre></div><h1 id="spark支持的四种运行方式"><a href="#spark支持的四种运行方式" class="header-anchor">#</a> spark支持的四种运行方式</h1> <ol><li>本地单机模式</li> <li>集群单机模式</li> <li>基于Mesos</li> <li>基于YARN</li></ol> <h1 id="spark集群的两类构成程序"><a href="#spark集群的两类构成程序" class="header-anchor">#</a> spark集群的两类构成程序</h1> <ol><li>驱动程序</li> <li>多个执行程序</li></ol> <p>spark中RDD的容错性：当某个节点或任务失败时(非用户代码错误引起，如硬件故障、网络不通等)，RDD或在余下的其他节点上自动重建、以便任务能最终完成</p> <p>分布式存储系统
cassandra dynamodb tair
CDN：内容分发网络</p></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/blog/bigData/hbase.html" class="prev">
        HBASE
      </a></span> <span class="next"><a href="/blog/bigData/luigi.html">
        Luigi和sciluigi
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"><!----></div></div>
    <script src="/blog/assets/js/app.48b65c17.js" defer></script><script src="/blog/assets/js/2.7ae4b6a2.js" defer></script><script src="/blog/assets/js/31.8bc7ae14.js" defer></script>
  </body>
</html>
